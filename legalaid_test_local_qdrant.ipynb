{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from qdrant_client import QdrantClient\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain import hub\n",
    "import os\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:47.293622Z",
     "start_time": "2025-01-28T07:52:43.121238Z"
    }
   },
   "id": "9997182d04be6f5",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "QDRANT_ARCH_LINUX_URL = os.environ[\"QDRANT_ARCH_LINUX_URL\"]\n",
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=\"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\"\n",
    "LANGSMITH_PROJECT=\"pr-linear-offense-26\"\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:47.311782Z",
     "start_time": "2025-01-28T07:52:47.303770Z"
    }
   },
   "id": "47790264e2826c08",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:51.631411Z",
     "start_time": "2025-01-28T07:52:47.316348Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "client = QdrantClient(url=QDRANT_ARCH_LINUX_URL)\n",
    "vector_store = QdrantVectorStore(client=client, embedding=embeddings, collection_name=\"legal_docs_ollama\")\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", api_key=OPENAI_API_KEY)\n",
    "#test_prompt = \"What are the things to be considered in invoking and proving psychological incapacity?\"\n",
    "#test_docs = vector_store.similarity_search(test_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\",api_key=LANGSMITH_API_KEY)\n",
    "example_messages = prompt.invoke({\"context\":\"(context goes here)\", \"question\":\"(question goes here)\"}).to_messages()\n",
    "assert len(example_messages)==1\n",
    "print(example_messages[0].content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:52.328093Z",
     "start_time": "2025-01-28T07:52:51.635255Z"
    }
   },
   "id": "a6b009d5bffedd68",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved 10 documents\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"],k=10)\n",
    "    print(f\"retrieved {len(retrieved_docs)} documents\")\n",
    "    print(\"****\")\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response0 = llm.invoke(messages)\n",
    "    return {\"answer\": response0.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "response = graph.invoke({\"question\": \"What are the things to be considered in invoking and proving psychological incapacity?\"})\n",
    "print(response[\"answer\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:53.902717Z",
     "start_time": "2025-01-28T07:52:52.333436Z"
    }
   },
   "id": "cd0718f8e8841cd9",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-28T07:52:53.908108Z",
     "start_time": "2025-01-28T07:52:53.904669Z"
    }
   },
   "id": "870ee1af2b949002",
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
