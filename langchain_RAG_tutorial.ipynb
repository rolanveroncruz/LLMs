{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports and setting environment vars"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da9c5aaf8cabe57"
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:33.591394Z",
     "start_time": "2025-01-25T09:40:33.584042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7efb4e9431e35782"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Indexing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d98e00894706deed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Document(s)\n",
    "Load a html webpage, and get only headers, titles, and contents(?).\n",
    "We expect only one document `assert len(docs)==1`\n",
    "We print the first 500 characters of the doc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae8fd2f5a88ed70"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95bc45b67aa09846"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters:43130\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "assert len(docs)==1\n",
    "print(f\"Total characters:{len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:33.838374Z",
     "start_time": "2025-01-25T09:40:33.593231Z"
    }
   },
   "id": "fe124c7df82c10dc",
   "execution_count": 136
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Documents\n",
    "We'll now split the document into snippets of 1000 characters each."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6bf8827984bb821"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:33.844978Z",
     "start_time": "2025-01-25T09:40:33.840Z"
    }
   },
   "id": "6d151bee35251acf",
   "execution_count": 137
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store Vectors\n",
    "We use OPENAPI for embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89c158ced0e75436"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=openai_api_key)\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:33.893655Z",
     "start_time": "2025-01-25T09:40:33.846037Z"
    }
   },
   "id": "c9837d26eb912004",
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store now contains 66 vectors.\n",
      "['4d6f9ca9-2dd3-49e6-8471-9a7897cb9652', '5d537c84-aa6e-444c-b2f0-f8e3cec579e7', 'c7d50493-edcf-495e-bd74-a770e4d468d8']\n"
     ]
    }
   ],
   "source": [
    "document_ids=vector_store.add_documents(all_splits)\n",
    "print(f\"vector store now contains {len(document_ids)} vectors.\")\n",
    "print(document_ids[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:37.463342Z",
     "start_time": "2025-01-25T09:40:33.895716Z"
    }
   },
   "id": "7c6854da278ced6b",
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieval and Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1453962ba441782"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=\"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\"\n",
    "LANGSMITH_PROJECT=\"pr-tragic-frenzy-11\"\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\",api_key=LANGSMITH_API_KEY)\n",
    "example_messages = prompt.invoke({\"context\":\"(context goes here)\", \"question\":\"(question goes here)\"}).to_messages()\n",
    "assert len(example_messages)==1\n",
    "print(example_messages[0].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:38.036641Z",
     "start_time": "2025-01-25T09:40:37.464955Z"
    }
   },
   "id": "4c481dac06fec31b",
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", api_key=OPENAI_API_KEY)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:38.102488Z",
     "start_time": "2025-01-25T09:40:38.039560Z"
    }
   },
   "id": "7b7ba03bf89efcb3",
   "execution_count": 141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state:State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state:State):\n",
    "    docs_content=\"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\":state[\"question\"], \"context\":docs_content})\n",
    "    response0 = llm.invoke(messages)\n",
    "    return {\"answer\":response0.content}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:38.107475Z",
     "start_time": "2025-01-25T09:40:38.103677Z"
    }
   },
   "id": "b18d657e28084db",
   "execution_count": 142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "graph_builder=StateGraph(State).add_sequence([retrieve,generate])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:38.111010Z",
     "start_time": "2025-01-25T09:40:38.108526Z"
    }
   },
   "id": "dbca2d4ea13b8321",
   "execution_count": 143
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph=graph_builder.compile()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:38.114556Z",
     "start_time": "2025-01-25T09:40:38.111850Z"
    }
   },
   "id": "1e5fd582f5841433",
   "execution_count": 144
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down a complex task into smaller, manageable steps or tasks. It allows an agent to plan ahead by identifying subgoals and using techniques like Chain of Thought (CoT) to enhance reasoning and performance. This can be achieved through simple prompts, task-specific instructions, or human inputs.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:40.700694Z",
     "start_time": "2025-01-25T09:40:38.117081Z"
    }
   },
   "id": "9bee182f39124d34",
   "execution_count": 145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:40:40.706084Z",
     "start_time": "2025-01-25T09:40:40.703034Z"
    }
   },
   "id": "6eb8c2826ad9efd7",
   "execution_count": 145
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
