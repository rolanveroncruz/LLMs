{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports and setting environment vars"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9da9c5aaf8cabe57"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:17:58.060823Z",
     "start_time": "2025-01-23T11:17:58.036704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7efb4e9431e35782"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Indexing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d98e00894706deed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Document(s)\n",
    "Load an html webpage, and get only headers, titles, and contents(?).\n",
    "We expect only one document `assert len(docs)==1`\n",
    "We print the first 500 characters of the doc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ae8fd2f5a88ed70"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "95bc45b67aa09846"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters:43130\n",
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "assert len(docs)==1\n",
    "print(f\"Total characters:{len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:500])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:19:18.132145Z",
     "start_time": "2025-01-23T11:18:02.519421Z"
    }
   },
   "id": "fe124c7df82c10dc",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Documents\n",
    "We'll now split the document into snippets of 1000 characters each."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6bf8827984bb821"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:19:56.303896Z",
     "start_time": "2025-01-23T11:19:56.297476Z"
    }
   },
   "id": "6d151bee35251acf",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Store Vectors\n",
    "We use OPENAPI for embeddings."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89c158ced0e75436"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=openai_api_key)\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:20:09.076550Z",
     "start_time": "2025-01-23T11:20:09.005910Z"
    }
   },
   "id": "c9837d26eb912004",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store now contains 66 vectors.\n",
      "['274d6e00-a0b5-4f7e-afb0-78a515a63600', '805bfff6-8d27-4fe8-af2b-67f2362f97ad', '4507f4cc-2493-460a-9e38-b7323b59f249']\n"
     ]
    }
   ],
   "source": [
    "document_ids=vector_store.add_documents(all_splits)\n",
    "print(f\"vector store now contains {len(document_ids)} vectors.\")\n",
    "print(document_ids[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:20:28.294090Z",
     "start_time": "2025-01-23T11:20:24.350955Z"
    }
   },
   "id": "7c6854da278ced6b",
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Retrieval and Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1453962ba441782"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "import getpass\n",
    "LANGSMITH_TRACING=True\n",
    "LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGSMITH_API_KEY=\"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\"\n",
    "LANGSMITH_PROJECT=\"pr-abandoned-toenail-3\"\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\",api_key=LANGSMITH_API_KEY)\n",
    "example_messages = prompt.invoke({\"context\":\"(context goes here)\", \"question\":\"(question goes here)\"}).to_messages()\n",
    "assert len(example_messages)==1\n",
    "print(example_messages[0].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:35:34.394456Z",
     "start_time": "2025-01-23T11:35:33.135998Z"
    }
   },
   "id": "4c481dac06fec31b",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:40:49.655466Z",
     "start_time": "2025-01-23T11:40:49.589452Z"
    }
   },
   "id": "7b7ba03bf89efcb3",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state:State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state:State):\n",
    "    docs_content=\"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\":state[\"question\"], \"context\":docs_content})\n",
    "    response0 = llm.invoke(messages)\n",
    "    return {\"answer\":response0.content}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:43:17.704479Z",
     "start_time": "2025-01-23T11:43:17.697063Z"
    }
   },
   "id": "b18d657e28084db",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "graph_builder=StateGraph(State).add_sequence([retrieve,generate])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:43:18.834690Z",
     "start_time": "2025-01-23T11:43:18.829650Z"
    }
   },
   "id": "dbca2d4ea13b8321",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph=graph_builder.compile()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:43:19.867751Z",
     "start_time": "2025-01-23T11:43:19.861782Z"
    }
   },
   "id": "1e5fd582f5841433",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down complex tasks into smaller, manageable steps to facilitate easier execution and understanding. It can involve techniques like Chain of Thought (CoT) prompting, where a model is guided to think step-by-step, or Tree of Thoughts, which explores multiple reasoning possibilities at each step. This approach improves performance on intricate tasks by making them simpler and allows for clearer interpretation of the model's reasoning process.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-23T11:43:33.464720Z",
     "start_time": "2025-01-23T11:43:20.717139Z"
    }
   },
   "id": "9bee182f39124d34",
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6eb8c2826ad9efd7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
